# generated by datamodel-codegen:
#   filename:  openapi.yaml
#   timestamp: 2021-12-31T02:51:56+00:00

from __future__ import annotations

from datetime import datetime
from enum import Enum
from typing import Annotated, Any, List, Optional

from pydantic import BaseModel, Field


class ValidationException(BaseModel):
    __root__: Any


class ConflictException(ValidationException):
    pass


class ThrottlingException(ValidationException):
    pass


class ServiceQuotaExceededException(ValidationException):
    pass


class AccessDeniedException(ValidationException):
    pass


class InternalServerException(ValidationException):
    pass


class ResourceNotFoundException(ValidationException):
    pass


class TagResourceResponse(BaseModel):
    pass


class UntagResourceResponse(TagResourceResponse):
    pass


class AmazonResourceArn(BaseModel):
    __root__: Annotated[str, Field(max_length=1011, min_length=1)]


class BoundedLengthString(BaseModel):
    __root__: Annotated[
        str, Field(max_length=5000, min_length=1, regex='[\\P{M}\\p{M}]{1,5000}')
    ]


class ComponentTimestampDelimiter(BaseModel):
    __root__: Annotated[
        str, Field(max_length=1, min_length=0, regex='^(\\-|\\_|\\s)?$')
    ]


class DatasetName(BaseModel):
    __root__: Annotated[
        str, Field(max_length=200, min_length=1, regex='^[0-9a-zA-Z_-]{1,200}$')
    ]


class NameOrArn(BaseModel):
    __root__: Annotated[
        str,
        Field(
            max_length=2048,
            min_length=1,
            regex='^[A-Za-z0-9][A-Za-z0-9:_/+=,@.-]{0,2048}$',
        ),
    ]


class IdempotenceToken(BaseModel):
    __root__: Annotated[
        str, Field(max_length=256, min_length=1, regex='\\p{ASCII}{1,256}')
    ]


class DatasetArn(BaseModel):
    __root__: Annotated[
        str,
        Field(
            max_length=2048,
            min_length=20,
            regex='arn:aws(-[^:]+)?:lookoutequipment:[a-zA-Z0-9\\-]*:[0-9]{12}:dataset\\/.+',
        ),
    ]


class DatasetStatus(Enum):
    CREATED = 'CREATED'
    INGESTION_IN_PROGRESS = 'INGESTION_IN_PROGRESS'
    ACTIVE = 'ACTIVE'


class ModelName(DatasetName):
    pass


class InferenceSchedulerName(DatasetName):
    pass


class DataDelayOffsetInMinutes(BaseModel):
    __root__: Annotated[int, Field(ge=0.0, le=60.0)]


class DataUploadFrequency(Enum):
    PT5M = 'PT5M'
    PT10M = 'PT10M'
    PT15M = 'PT15M'
    PT30M = 'PT30M'
    PT1H = 'PT1H'


class IamRoleArn(BaseModel):
    __root__: Annotated[
        str,
        Field(
            max_length=2048,
            min_length=20,
            regex='arn:aws(-[^:]+)?:iam::[0-9]{12}:role/.+',
        ),
    ]


class InferenceSchedulerArn(BaseModel):
    __root__: Annotated[
        str,
        Field(
            max_length=2048,
            min_length=20,
            regex='arn:aws(-[^:]+)?:lookoutequipment:[a-zA-Z0-9\\-]*:[0-9]{12}:inference-scheduler\\/.+',
        ),
    ]


class InferenceSchedulerStatus(Enum):
    PENDING = 'PENDING'
    RUNNING = 'RUNNING'
    STOPPING = 'STOPPING'
    STOPPED = 'STOPPED'


class DatasetIdentifier(DatasetName):
    pass


class Timestamp(BaseModel):
    __root__: datetime


class OffCondition(BaseModel):
    __root__: Annotated[str, Field(max_length=2048, min_length=1)]


class ModelArn(BaseModel):
    __root__: Annotated[
        str,
        Field(
            max_length=2048,
            min_length=20,
            regex='arn:aws(-[^:]+)?:lookoutequipment:[a-zA-Z0-9\\-]*:[0-9]{12}:model\\/.+',
        ),
    ]


class ModelStatus(Enum):
    IN_PROGRESS = 'IN_PROGRESS'
    SUCCESS = 'SUCCESS'
    FAILED = 'FAILED'


class IngestionJobId(BaseModel):
    __root__: Annotated[str, Field(max_length=32, regex='[A-Fa-f0-9]{0,32}')]


class TargetSamplingRate(Enum):
    PT1S = 'PT1S'
    PT5S = 'PT5S'
    PT10S = 'PT10S'
    PT15S = 'PT15S'
    PT30S = 'PT30S'
    PT1M = 'PT1M'
    PT5M = 'PT5M'
    PT10M = 'PT10M'
    PT15M = 'PT15M'
    PT30M = 'PT30M'
    PT1H = 'PT1H'


class InlineDataSchema(BaseModel):
    __root__: Annotated[str, Field(max_length=1000000, min_length=1)]


class DatasetSummary(BaseModel):
    """
    Contains information about the specific data set, including name, ARN, and status.
    """

    DatasetName: Optional[DatasetName] = None
    DatasetArn: Optional[DatasetArn] = None
    Status: Optional[DatasetStatus] = None
    CreatedAt: Optional[Timestamp] = None


class DatasetSummaries(BaseModel):
    __root__: List[DatasetSummary]


class InferenceSchedulerIdentifier(DatasetName):
    pass


class KmsKeyArn(BaseModel):
    __root__: Annotated[
        str,
        Field(
            max_length=1024,
            min_length=1,
            regex='arn:aws[a-z\\-]*:kms:[a-z0-9\\-]*:\\d{12}:[\\w\\-\\/]+',
        ),
    ]


class ModelMetrics(BaseModel):
    __root__: Annotated[str, Field(max_length=50000, min_length=1)]


class FileNameTimestampFormat(BaseModel):
    __root__: Annotated[str, Field(regex='^EPOCH|yyyy-MM-dd-HH-mm-ss|yyyyMMddHHmmss$')]


class TimeZoneOffset(BaseModel):
    __root__: Annotated[str, Field(regex='^(\\+|\\-)[0-9]{2}\\:[0-9]{2}$')]


class InferenceInputNameConfiguration(BaseModel):
    """
    Specifies configuration information for the input data for the inference, including timestamp format and delimiter.
    """

    TimestampFormat: Optional[FileNameTimestampFormat] = None
    ComponentTimestampDelimiter: Optional[ComponentTimestampDelimiter] = None


class S3Bucket(BaseModel):
    __root__: Annotated[
        str,
        Field(
            max_length=63, min_length=3, regex='^[a-z0-9][\\.\\-a-z0-9]{1,61}[a-z0-9]$'
        ),
    ]


class S3Prefix(BaseModel):
    __root__: Annotated[
        str,
        Field(max_length=1024, min_length=0, regex='(^$)|([\\P{M}\\p{M}]{1,1023}/$)'),
    ]


class InferenceSchedulerSummary(BaseModel):
    """
    Contains information about the specific inference scheduler, including data delay offset, model name and ARN, status, and so on.
    """

    ModelName: Optional[ModelName] = None
    ModelArn: Optional[ModelArn] = None
    InferenceSchedulerName: Optional[InferenceSchedulerName] = None
    InferenceSchedulerArn: Optional[InferenceSchedulerArn] = None
    Status: Optional[InferenceSchedulerStatus] = None
    DataDelayOffsetInMinutes: Optional[DataDelayOffsetInMinutes] = None
    DataUploadFrequency: Optional[DataUploadFrequency] = None


class InferenceSchedulerSummaries(BaseModel):
    __root__: List[InferenceSchedulerSummary]


class IngestionS3InputConfiguration(BaseModel):
    """
    Specifies S3 configuration information for the input data for the data ingestion job.
    """

    Bucket: S3Bucket
    Prefix: Optional[S3Prefix] = None


class LabelsS3InputConfiguration(IngestionS3InputConfiguration):
    """
    The location information (prefix and bucket name) for the s3 location being used for label data.
    """

    pass


class NextToken(BaseModel):
    __root__: Annotated[str, Field(max_length=8192, regex='\\p{ASCII}{0,8192}')]


class MaxResults(BaseModel):
    __root__: Annotated[int, Field(ge=1.0, le=500.0)]


class ModelSummary(BaseModel):
    """
    Provides information about the specified ML model, including dataset and model names and ARNs, as well as status.
    """

    ModelName: Optional[ModelName] = None
    ModelArn: Optional[ModelArn] = None
    DatasetName: Optional[DatasetName] = None
    DatasetArn: Optional[DatasetArn] = None
    Status: Optional[ModelStatus] = None
    CreatedAt: Optional[Timestamp] = None


class S3Key(BaseModel):
    __root__: Annotated[
        str, Field(max_length=1024, min_length=1, regex='[\\P{M}\\p{M}]{1,1024}[^/]$')
    ]


class TagKey(BaseModel):
    __root__: Annotated[
        str, Field(max_length=128, min_length=1, regex='^(?!aws:)[a-zA-Z+-=._:/]+$')
    ]


class TagValue(BaseModel):
    __root__: Annotated[
        str, Field(max_length=256, min_length=0, regex='[\\s\\w+-=\\.:/@]*')
    ]


class Tag(BaseModel):
    """
    A tag is a key-value pair that can be added to a resource as metadata.
    """

    Key: TagKey
    Value: TagValue


class TagKeyList(BaseModel):
    __root__: Annotated[List[TagKey], Field(max_items=200, min_items=0)]


class CreateDatasetResponse(BaseModel):
    DatasetName: Optional[DatasetName] = None
    DatasetArn: Optional[DatasetArn] = None
    Status: Optional[DatasetStatus] = None


class CreateInferenceSchedulerResponse(BaseModel):
    InferenceSchedulerArn: Optional[InferenceSchedulerArn] = None
    InferenceSchedulerName: Optional[InferenceSchedulerName] = None
    Status: Optional[InferenceSchedulerStatus] = None


class CreateModelResponse(BaseModel):
    ModelArn: Optional[ModelArn] = None
    Status: Optional[ModelStatus] = None


class DeleteDatasetRequest(BaseModel):
    DatasetName: DatasetIdentifier


class DeleteInferenceSchedulerRequest(BaseModel):
    InferenceSchedulerName: InferenceSchedulerIdentifier


class DeleteModelRequest(BaseModel):
    ModelName: ModelName


class DescribeDataIngestionJobRequest(BaseModel):
    JobId: IngestionJobId


class DescribeDatasetRequest(BaseModel):
    DatasetName: DatasetIdentifier


class DescribeInferenceSchedulerRequest(BaseModel):
    InferenceSchedulerName: InferenceSchedulerIdentifier


class DescribeModelRequest(BaseModel):
    ModelName: ModelName


class ListDataIngestionJobsRequest(BaseModel):
    DatasetName: Optional[DatasetName] = None
    NextToken: Optional[NextToken] = None
    MaxResults: Optional[MaxResults] = None
    Status: Optional[ModelStatus] = None


class ListDatasetsResponse(BaseModel):
    NextToken: Optional[NextToken] = None
    DatasetSummaries: Optional[DatasetSummaries] = None


class ListDatasetsRequest(BaseModel):
    NextToken: Optional[NextToken] = None
    MaxResults: Optional[MaxResults] = None
    DatasetNameBeginsWith: Optional[DatasetName] = None


class ListInferenceExecutionsRequest(BaseModel):
    NextToken: Optional[NextToken] = None
    MaxResults: Optional[MaxResults] = None
    InferenceSchedulerName: InferenceSchedulerIdentifier
    DataStartTimeAfter: Optional[Timestamp] = None
    DataEndTimeBefore: Optional[Timestamp] = None
    Status: Optional[ModelStatus] = None


class ListInferenceSchedulersResponse(BaseModel):
    NextToken: Optional[NextToken] = None
    InferenceSchedulerSummaries: Optional[InferenceSchedulerSummaries] = None


class ListInferenceSchedulersRequest(BaseModel):
    NextToken: Optional[NextToken] = None
    MaxResults: Optional[MaxResults] = None
    InferenceSchedulerNameBeginsWith: Optional[InferenceSchedulerIdentifier] = None
    ModelName: Optional[ModelName] = None


class ListModelsRequest(BaseModel):
    NextToken: Optional[NextToken] = None
    MaxResults: Optional[MaxResults] = None
    Status: Optional[ModelStatus] = None
    ModelNameBeginsWith: Optional[ModelName] = None
    DatasetNameBeginsWith: Optional[DatasetName] = None


class ListTagsForResourceRequest(BaseModel):
    ResourceArn: AmazonResourceArn


class StartDataIngestionJobResponse(BaseModel):
    JobId: Optional[IngestionJobId] = None
    Status: Optional[ModelStatus] = None


class StartInferenceSchedulerResponse(BaseModel):
    ModelArn: Optional[ModelArn] = None
    ModelName: Optional[ModelName] = None
    InferenceSchedulerName: Optional[InferenceSchedulerName] = None
    InferenceSchedulerArn: Optional[InferenceSchedulerArn] = None
    Status: Optional[InferenceSchedulerStatus] = None


class StartInferenceSchedulerRequest(BaseModel):
    InferenceSchedulerName: InferenceSchedulerIdentifier


class StopInferenceSchedulerResponse(StartInferenceSchedulerResponse):
    pass


class StopInferenceSchedulerRequest(BaseModel):
    InferenceSchedulerName: InferenceSchedulerIdentifier


class UntagResourceRequest(BaseModel):
    ResourceArn: AmazonResourceArn
    TagKeys: TagKeyList


class DatasetSchema(BaseModel):
    """
    Provides information about the data schema used with the given dataset.
    """

    InlineDataSchema: Optional[InlineDataSchema] = None


class TagList(BaseModel):
    __root__: Annotated[List[Tag], Field(max_items=200, min_items=0)]


class LabelsInputConfiguration(BaseModel):
    """
    Contains the configuration information for the S3 location being used to hold label data.
    """

    S3InputConfiguration: LabelsS3InputConfiguration


class DataPreProcessingConfiguration(BaseModel):
    """
    <p>The configuration is the <code>TargetSamplingRate</code>, which is the sampling rate of the data after post processing by Amazon Lookout for Equipment. For example, if you provide data that has been collected at a 1 second level and you want the system to resample the data at a 1 minute rate before training, the <code>TargetSamplingRate</code> is 1 minute.</p> <p>When providing a value for the <code>TargetSamplingRate</code>, you must attach the prefix "PT" to the rate you want. The value for a 1 second rate is therefore <i>PT1S</i>, the value for a 15 minute rate is <i>PT15M</i>, and the value for a 1 hour rate is <i>PT1H</i> </p>
    """

    TargetSamplingRate: Optional[TargetSamplingRate] = None


class IngestionInputConfiguration(BaseModel):
    """
    Specifies configuration information for the input data for the data ingestion job, including input data S3 location.
    """

    S3InputConfiguration: IngestionS3InputConfiguration


class S3Object(BaseModel):
    """
    Contains information about an S3 bucket.
    """

    Bucket: S3Bucket
    Key: S3Key


class InferenceS3InputConfiguration(IngestionS3InputConfiguration):
    """
    Specifies configuration information for the input data for the inference, including input data S3 location.
    """

    pass


class InferenceS3OutputConfiguration(IngestionS3InputConfiguration):
    """
    Specifies configuration information for the output results from the inference, including output S3 location.
    """

    pass


class ModelSummaries(BaseModel):
    __root__: List[ModelSummary]


class CreateDatasetRequest(BaseModel):
    DatasetName: DatasetName
    DatasetSchema: DatasetSchema
    ServerSideKmsKeyId: Optional[NameOrArn] = None
    ClientToken: IdempotenceToken
    Tags: Optional[TagList] = None


class CreateModelRequest(BaseModel):
    ModelName: ModelName
    DatasetName: DatasetIdentifier
    DatasetSchema: Optional[DatasetSchema] = None
    LabelsInputConfiguration: Optional[LabelsInputConfiguration] = None
    ClientToken: IdempotenceToken
    TrainingDataStartTime: Optional[Timestamp] = None
    TrainingDataEndTime: Optional[Timestamp] = None
    EvaluationDataStartTime: Optional[Timestamp] = None
    EvaluationDataEndTime: Optional[Timestamp] = None
    RoleArn: Optional[IamRoleArn] = None
    DataPreProcessingConfiguration: Optional[DataPreProcessingConfiguration] = None
    ServerSideKmsKeyId: Optional[NameOrArn] = None
    Tags: Optional[TagList] = None
    OffCondition: Optional[OffCondition] = None


class DescribeDataIngestionJobResponse(BaseModel):
    JobId: Optional[IngestionJobId] = None
    DatasetArn: Optional[DatasetArn] = None
    IngestionInputConfiguration: Optional[IngestionInputConfiguration] = None
    RoleArn: Optional[IamRoleArn] = None
    CreatedAt: Optional[Timestamp] = None
    Status: Optional[ModelStatus] = None
    FailedReason: Optional[BoundedLengthString] = None


class DescribeDatasetResponse(BaseModel):
    DatasetName: Optional[DatasetName] = None
    DatasetArn: Optional[DatasetArn] = None
    CreatedAt: Optional[Timestamp] = None
    LastUpdatedAt: Optional[Timestamp] = None
    Status: Optional[DatasetStatus] = None
    Schema: Optional[InlineDataSchema] = None
    ServerSideKmsKeyId: Optional[KmsKeyArn] = None
    IngestionInputConfiguration: Optional[IngestionInputConfiguration] = None


class DescribeModelResponse(BaseModel):
    ModelName: Optional[ModelName] = None
    ModelArn: Optional[ModelArn] = None
    DatasetName: Optional[DatasetName] = None
    DatasetArn: Optional[DatasetArn] = None
    Schema: Optional[InlineDataSchema] = None
    LabelsInputConfiguration: Optional[LabelsInputConfiguration] = None
    TrainingDataStartTime: Optional[Timestamp] = None
    TrainingDataEndTime: Optional[Timestamp] = None
    EvaluationDataStartTime: Optional[Timestamp] = None
    EvaluationDataEndTime: Optional[Timestamp] = None
    RoleArn: Optional[IamRoleArn] = None
    DataPreProcessingConfiguration: Optional[DataPreProcessingConfiguration] = None
    Status: Optional[ModelStatus] = None
    TrainingExecutionStartTime: Optional[Timestamp] = None
    TrainingExecutionEndTime: Optional[Timestamp] = None
    FailedReason: Optional[BoundedLengthString] = None
    ModelMetrics: Optional[ModelMetrics] = None
    LastUpdatedTime: Optional[Timestamp] = None
    CreatedAt: Optional[Timestamp] = None
    ServerSideKmsKeyId: Optional[KmsKeyArn] = None
    OffCondition: Optional[OffCondition] = None


class ListModelsResponse(BaseModel):
    NextToken: Optional[NextToken] = None
    ModelSummaries: Optional[ModelSummaries] = None


class ListTagsForResourceResponse(BaseModel):
    Tags: Optional[TagList] = None


class StartDataIngestionJobRequest(BaseModel):
    DatasetName: DatasetIdentifier
    IngestionInputConfiguration: IngestionInputConfiguration
    RoleArn: IamRoleArn
    ClientToken: IdempotenceToken


class TagResourceRequest(BaseModel):
    ResourceArn: AmazonResourceArn
    Tags: TagList


class InferenceInputConfiguration(BaseModel):
    """
    Specifies configuration information for the input data for the inference, including S3 location of input data..
    """

    S3InputConfiguration: Optional[InferenceS3InputConfiguration] = None
    InputTimeZoneOffset: Optional[TimeZoneOffset] = None
    InferenceInputNameConfiguration: Optional[InferenceInputNameConfiguration] = None


class InferenceOutputConfiguration(BaseModel):
    """
    Specifies configuration information for the output results from for the inference, including KMS key ID and output S3 location.
    """

    S3OutputConfiguration: InferenceS3OutputConfiguration
    KmsKeyId: Optional[NameOrArn] = None


class DataIngestionJobSummary(BaseModel):
    """
    Provides information about a specified data ingestion job, including dataset information, data ingestion configuration, and status.
    """

    JobId: Optional[IngestionJobId] = None
    DatasetName: Optional[DatasetName] = None
    DatasetArn: Optional[DatasetArn] = None
    IngestionInputConfiguration: Optional[IngestionInputConfiguration] = None
    Status: Optional[ModelStatus] = None


class DataIngestionJobSummaries(BaseModel):
    __root__: List[DataIngestionJobSummary]


class InferenceExecutionSummary(BaseModel):
    """
    Contains information about the specific inference execution, including input and output data configuration, inference scheduling information, status, and so on.
    """

    ModelName: Optional[ModelName] = None
    ModelArn: Optional[ModelArn] = None
    InferenceSchedulerName: Optional[InferenceSchedulerName] = None
    InferenceSchedulerArn: Optional[InferenceSchedulerArn] = None
    ScheduledStartTime: Optional[Timestamp] = None
    DataStartTime: Optional[Timestamp] = None
    DataEndTime: Optional[Timestamp] = None
    DataInputConfiguration: Optional[InferenceInputConfiguration] = None
    DataOutputConfiguration: Optional[InferenceOutputConfiguration] = None
    CustomerResultObject: Optional[S3Object] = None
    Status: Optional[ModelStatus] = None
    FailedReason: Optional[BoundedLengthString] = None


class InferenceExecutionSummaries(BaseModel):
    __root__: List[InferenceExecutionSummary]


class CreateInferenceSchedulerRequest(BaseModel):
    ModelName: ModelName
    InferenceSchedulerName: InferenceSchedulerName
    DataDelayOffsetInMinutes: Optional[DataDelayOffsetInMinutes] = None
    DataUploadFrequency: DataUploadFrequency
    DataInputConfiguration: InferenceInputConfiguration
    DataOutputConfiguration: InferenceOutputConfiguration
    RoleArn: IamRoleArn
    ServerSideKmsKeyId: Optional[NameOrArn] = None
    ClientToken: IdempotenceToken
    Tags: Optional[TagList] = None


class DescribeInferenceSchedulerResponse(BaseModel):
    ModelArn: Optional[ModelArn] = None
    ModelName: Optional[ModelName] = None
    InferenceSchedulerName: Optional[InferenceSchedulerName] = None
    InferenceSchedulerArn: Optional[InferenceSchedulerArn] = None
    Status: Optional[InferenceSchedulerStatus] = None
    DataDelayOffsetInMinutes: Optional[DataDelayOffsetInMinutes] = None
    DataUploadFrequency: Optional[DataUploadFrequency] = None
    CreatedAt: Optional[Timestamp] = None
    UpdatedAt: Optional[Timestamp] = None
    DataInputConfiguration: Optional[InferenceInputConfiguration] = None
    DataOutputConfiguration: Optional[InferenceOutputConfiguration] = None
    RoleArn: Optional[IamRoleArn] = None
    ServerSideKmsKeyId: Optional[KmsKeyArn] = None


class ListDataIngestionJobsResponse(BaseModel):
    NextToken: Optional[NextToken] = None
    DataIngestionJobSummaries: Optional[DataIngestionJobSummaries] = None


class ListInferenceExecutionsResponse(BaseModel):
    NextToken: Optional[NextToken] = None
    InferenceExecutionSummaries: Optional[InferenceExecutionSummaries] = None


class UpdateInferenceSchedulerRequest(BaseModel):
    InferenceSchedulerName: InferenceSchedulerIdentifier
    DataDelayOffsetInMinutes: Optional[DataDelayOffsetInMinutes] = None
    DataUploadFrequency: Optional[DataUploadFrequency] = None
    DataInputConfiguration: Optional[InferenceInputConfiguration] = None
    DataOutputConfiguration: Optional[InferenceOutputConfiguration] = None
    RoleArn: Optional[IamRoleArn] = None
